# Building a Neural Network

This project aims at creating a neural network from scratch, to apprehend not only the theoretical part but also the practical part.

## Table of Contents

1. [Introduction](#introduction)
    
    1.1. [Why build a Neural Network from scratch?](#why-building-a-neural-network-from-scratch)
    
    1.2. [What is the goal of this project?](#what-is-the-goal-of-this-project)

2. [Neural Network notions](#notions)

    2.1. [Neural Network](#neural-network)
    
    2.2. [Activation Function](#activation-function)
    
    2.3. [Loss Function](#loss-function)
    
    2.4. [Gradient Descent](#gradient-descent)
    
    2.5. [Backpropagation](#backpropagation)

3. [Notations](#notations)
    
4. [Implementation](#implementation)

5. [First batch of results](#results)

6. [Optimization](#optimization)

7. [Second batch of results](#results)

8. [Conclusion](#conclusion)


## Introduction <a name="introduction"></a>

### Why build a Neural Network from scratch? <a name="why-building-a-neural-network-from-scratch"></a>

I'm really into data and AI, so I chose to work on data science projects on the side. Among the algorithms to learn are neural networks.
I believe that building a neural network from scratch is a great way to understand how it works. It allows you to apprehend the theoretical part but also the practical part. It is a great way to understand the different components of a neural network and how they interact with each other.
Then, explaining the code to someone else is a great way to consolidate the knowledge acquired. So I hope the documentation will be clear enough for you to understand how to build a NN. That would mean I'm not too bad at it! ^^

### What is the goal of this project? <a name="what-is-the-goal-of-this-project"></a>


## Neural Network notions <a name="notions"></a>

In this section, I will explain the different notions that are important to understand when building a neural network.

### Neural Network <a name="neural-network"></a>





### Activation Function <a name="activation-function"></a>

### Loss Function <a name="loss-function"></a>

### Gradient Descent <a name="gradient-descent"></a>

### Backpropagation <a name="backpropagation"></a>

## Notations <a name="notations"></a>

## Implementation <a name="implementation"></a>

## First batch of results <a name="results"></a>

## Optimization <a name="optimization"></a>

## Second batch of results <a name="results"></a>

## Conclusion <a name="conclusion"></a>







